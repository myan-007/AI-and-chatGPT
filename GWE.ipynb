{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22f0232a-375f-4c40-9462-324b909f72ef",
   "metadata": {},
   "source": [
    "### BERT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d8b899a-d020-4fce-a161-1f6cf8653ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/meet/Documents/python/projects/LLM_WE/venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar word to 'Panamera': BMW_X6\n",
      "All similarities: [('BMW_X6', 0.4768236997788239), ('Macan', 0.4240032517990302), ('Car', 0.37994390226362995), ('Boxster', 0.3322195664028227), ('Porsche', 0.29447236004579835), ('Models', 0.2554825586111331), ('turismo', 0.11738918452304026)]\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "\n",
    "def get_word_embedding(word):\n",
    "    inputs = tokenizer(word, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        outputs = bert(**inputs)\n",
    "    word_embedding = outputs.last_hidden_state[0][1].numpy()\n",
    "    return word_embedding\n",
    "\n",
    "rims_embedding = get_word_embedding(\"Panamera\")\n",
    "\n",
    "words_to_compare = [\"turismo\", \"Macan\", \"Car\", \"Models\", \"Porsche\",\"Boxster\",\"BMW_X6\"]\n",
    "\n",
    "def cosine_similarity(emb1,emb2):\n",
    "    return 1 - cosine(emb1,emb2)\n",
    "\n",
    "similarities = {}\n",
    "for word in words_to_compare:\n",
    "    word_embedding = get_word_embedding(word)\n",
    "    similarity = cosine_similarity(rims_embedding, word_embedding)\n",
    "    similarities[word] = similarity\n",
    "\n",
    "sorted_similar_words = sorted(similarities.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "\n",
    "print(\"Most similar word to 'Panamera':\", sorted_similar_words[0][0])\n",
    "print(\"All similarities:\", sorted_similar_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bb2746-7a36-41f3-b5c4-c42a555feb0d",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c89d79c-5990-4edd-87ec-e6fe133e3a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "model_path = './GoogleNews-vectors-negative300.bin.gz'\n",
    "word2vec = KeyedVectors.load_word2vec_format(model_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04296470-2744-4c17-a285-8baf76c9ee6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words similar to 'Panamera': [('Boxster', 0.7418075203895569), ('Porsche_Panamera', 0.7396426200866699), ('coupé', 0.7206888198852539), ('Passat_CC', 0.7171149849891663), ('BMW_X6', 0.7134248614311218)]\n"
     ]
    }
   ],
   "source": [
    "similar_words = word2vec.most_similar('Panamera', topn=5)\n",
    "print(\"Words similar to 'Panamera':\", similar_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1eefc4a-6abd-4604-b203-73fc52c9a477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words similar to 'turismo': [('nuevos', 0.6451931595802307), ('la_próxima', 0.6395909190177917), ('ciudad', 0.6383398175239563), ('speciale', 0.6336588859558105), ('del_mundo', 0.6315416097640991)]\n"
     ]
    }
   ],
   "source": [
    "similar_words = word2vec.most_similar('turismo', topn=5)\n",
    "print(\"Words similar to 'turismo':\", similar_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fdc189d-0c6c-409c-8062-0db1c9782931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words similar to 'turismo': [('ER_Ejercito', 0.5041291117668152), ('Daligdig', 0.4992683529853821), ('Dewa_Made', 0.49745988845825195), ('Juan_Babauta', 0.4964611232280731), ('Rahman_Nava', 0.4960399866104126)]\n"
     ]
    }
   ],
   "source": [
    "similar_words = word2vec.most_similar('Macan', topn=5)\n",
    "print(\"Words similar to 'turismo':\", similar_words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
